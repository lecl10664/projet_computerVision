{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd80b093",
   "metadata": {},
   "source": [
    "# STEP B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71374866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def read_image_and_compute_keypoints(object_imgs, scene_imgs, detector):\n",
    "    imgs_dict = {}\n",
    "\n",
    "    for name_img in object_imgs:\n",
    "        img_load = cv2.imread('models/' + name_img + '.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        \"\"\"\n",
    "        # Enlever le centre de l'image\n",
    "        row = int(img_load.shape[0]/2)\n",
    "        col = int(img_load.shape[1]/2)\n",
    "        pour = 0.5\n",
    "        new_color = 255 # White\n",
    "        img_load[int(row - row*pour) : int(row + row*pour), int(col - col*pour): int(col + col*pour)] = new_color\n",
    "        #\n",
    "        \"\"\"\n",
    "\n",
    "        kp, des = detector.detectAndCompute(img_load, None)\n",
    "        imgs_dict[name_img] = {'kp': kp, 'des': des, 'shape': img_load.shape}\n",
    "\n",
    "    for name_img in scene_imgs:\n",
    "        img_load = cv2.imread('scenes/' + name_img + '.png', cv2.IMREAD_GRAYSCALE)\n",
    "        kp, des = detector.detectAndCompute(img_load, None)\n",
    "        imgs_dict[name_img] = {'kp': kp, 'des': des, 'shape': img_load.shape}\n",
    "\n",
    "    return imgs_dict\n",
    "\n",
    "def matching_and_localize_objects_in_scene(imgs_dict, name_scene_img, ratio_test=0.45):\n",
    "    all_scene_corners = {}\n",
    "    all_good ={}\n",
    "    for name in object_imgs:\n",
    "        object_des, object_kp = imgs_dict[name]['des'], imgs_dict[name]['kp']\n",
    "        scene_des, scene_kp = imgs_dict[name_scene_img]['des'], imgs_dict[name_scene_img]['kp']\n",
    "        \n",
    "        #-- matching\n",
    "        matches = matcher.knnMatch(object_des, scene_des, k=2)\n",
    "    \n",
    "        #-- store all the good matches as per Lowe's ratio test.\n",
    "        good = []\n",
    "        for m,n in matches:\n",
    "            if m.distance < ratio_test*n.distance:\n",
    "                good.append(m)\n",
    "                \n",
    "        if len(good) > 30:        \n",
    "            #-- Get the keypoints from the good matches\n",
    "            object_good_kp = np.float32([ object_kp[m.queryIdx].pt for m in good ])\n",
    "            scene_good_kp = np.float32([ scene_kp[m.trainIdx].pt for m in good ])   \n",
    "\n",
    "\n",
    "            #-- Get the corners of object\n",
    "            h,w = imgs_dict[name]['shape'][0:2]\n",
    "            object_corners = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "\n",
    "            #-- Get the homography of object/scene\n",
    "            H, _ =  cv2.findHomography(object_good_kp, scene_good_kp, cv2.RANSAC, 5.0)\n",
    "\n",
    "            #-- Get the corners of object in scene\n",
    "            scene_corners = cv2.perspectiveTransform(object_corners, H)\n",
    "\n",
    "\n",
    "            all_scene_corners[name] = scene_corners\n",
    "            all_good[name] = good\n",
    "        \n",
    "    return all_scene_corners, all_good\n",
    "\n",
    "def check_best_color_matches(all_scene_corners, name_scene_img):\n",
    "    \n",
    "    scene_img_bgr = cv2.imread('scenes/' + name_scene_img + '.png')\n",
    "    best_all_scene_corners = {}\n",
    "    \n",
    "    for name in all_scene_corners.keys():\n",
    "\n",
    "        x_min = max(int(np.min(all_scene_corners[name], axis=0)[0][0]), 0)\n",
    "        y_min = max(int(np.min(all_scene_corners[name], axis=0)[0][1]), 0)\n",
    "        x_max = int(np.max(all_scene_corners[name], axis=0)[0][0])\n",
    "        y_max = int(np.max(all_scene_corners[name], axis=0)[0][1])\n",
    "        \n",
    "        object_img_bgr = cv2.imread('models/' + name + '.jpg')\n",
    "        \n",
    "        object_img_mean_color = object_img_bgr.mean(axis=0).mean(axis=0)\n",
    "        object_in_scene_img = scene_img_bgr[y_min:y_max,x_min:x_max]\n",
    "        object_in_scene_img_mean_color = object_in_scene_img.mean(axis=0).mean(axis=0)   \n",
    "        color_diff = np.sqrt(np.sum([value ** 2 for value in abs(object_img_mean_color - object_in_scene_img_mean_color)]))\n",
    "        \n",
    "        #color_diff = (np.sum([value **2 for value in (object_img_mean_color - object_in_scene_img_mean_color)]))/4\n",
    "        \n",
    "        if color_diff < 60:\n",
    "            best_all_scene_corners[name] = all_scene_corners[name]\n",
    "        \n",
    "    return best_all_scene_corners\n",
    "\n",
    "def drawn_object_lines_in_scene(img_scene, best_all_scene_corners):\n",
    "    for name in best_all_scene_corners.keys():\n",
    "        scene_corners = best_all_scene_corners[name]\n",
    "        img_scene = cv2.polylines(img_scene, [np.int32(scene_corners)], \n",
    "                                  isClosed=True, color=(0,255,0), thickness=5)\n",
    "    return img_scene\n",
    "\n",
    "def print_object_found(best_all_scene_corners):\n",
    "    for name in best_all_scene_corners.keys():  \n",
    "        x_min = max(int(np.min(best_all_scene_corners[name], axis=0)[0][0]), 0)\n",
    "        y_min = max(int(np.min(best_all_scene_corners[name], axis=0)[0][1]), 0)\n",
    "        x_max = int(np.max(best_all_scene_corners[name], axis=0)[0][0])\n",
    "        y_max = int(np.max(best_all_scene_corners[name], axis=0)[0][1])\n",
    "        \n",
    "        print('Product {} - {} instance/s found:'.format(name, 1))\n",
    "        print('\\tInstance {} position: {}, width: {}px, height: {}px'.format(1, (x_min, y_min), (x_max-x_min), (y_max-y_min)))\n",
    "    \n",
    "    print('_' * 80 + '\\n')\n",
    "\n",
    "def stepA():\n",
    "    \n",
    "    detector = cv2.SIFT_create()\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "\n",
    "        # Defining parameters for algorithm \n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "\n",
    "        # Defining search params.\n",
    "        # checks=50 specifies the number of times the trees in the index should be recursively traversed.\n",
    "        # Higher values gives better precision, but also takes more time\n",
    "    search_params = dict(checks = 50)\n",
    "\n",
    "        # Initializing matcher\n",
    "    matcher = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    #matcher = cv2.DescriptorMatcher_create(cv2.DescriptorMatcher_FLANNBASED)\n",
    "    \n",
    "    imgs_dict = read_image_and_compute_keypoints(object_imgs, scene_imgs, detector)\n",
    "    \n",
    "    \n",
    "    for scene_name in scene_imgs:\n",
    "        \n",
    "        all_scene_corners, all_good= matching_and_localize_objects_in_scene(imgs_dict, scene_name)\n",
    "        \n",
    "        best_all_scene_corners = check_best_color_matches(all_scene_corners , scene_name)\n",
    "        \n",
    "        \n",
    "        img_scene_rgb = cv2.cvtColor(cv2.imread('scenes/' + scene_name + '.png'), cv2.COLOR_BGR2RGB)\n",
    "        img_scene_rgb = drawn_object_lines_in_scene(img_scene_rgb, best_all_scene_corners)\n",
    "\n",
    "        \n",
    "        print('Scene {} :'.format(scene_name))\n",
    "        plt.imshow(img_scene_rgb)\n",
    "        plt.show()\n",
    "        print_object_found(best_all_scene_corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8a38631",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- bank of image step B\n",
    "object_imgs = ['0', '1', '11', '19', '24', '25', '26']\n",
    "#object_imgs = ['0', '11']\n",
    "scene_imgs = ['m1', 'm2', 'm3', 'm4', 'm5']\n",
    "\n",
    "detector = cv2.SIFT_create()\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks = 50)\n",
    "matcher = cv2.FlannBasedMatcher(index_params, search_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d375faca",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_dict = read_image_and_compute_keypoints(object_imgs, scene_imgs, detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0f60c784",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_hough_space' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1c/xftq6kyj3_vbbmvfzx260p700000gn/T/ipykernel_2188/1335629754.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# create hough space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mhough_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_hough_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgood_matches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkp_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkp_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_xc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_yc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'create_hough_space' is not defined"
     ]
    }
   ],
   "source": [
    "for name in object_imgs:\n",
    "    object_des, object_kp = imgs_dict[name]['des'], imgs_dict[name]['kp']\n",
    "    scene_des, scene_kp = imgs_dict['m1']['des'], imgs_dict['m1']['kp']\n",
    "    \n",
    "    #-- matching\n",
    "    matches = matcher.knnMatch(object_des, scene_des, k=2)\n",
    "\n",
    "    #-- store all the good matches as per Lowe's ratio test.\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.5*n.distance:\n",
    "            good.append(m)\n",
    "    \n",
    "    #-- barycenter of found object keypoint \n",
    "    object_good_kp = [ object_kp[m.queryIdx] for m in good ]\n",
    "    \n",
    "    object_xc = np.mean([ kp.pt[0] for kp in object_good_kp ], dtype='float')\n",
    "    object_yc = np.mean([ kp.pt[1] for kp in object_good_kp ], dtype='float')\n",
    "    \n",
    "    # create hough space \n",
    "    # map of hough space kp_train_idx -> map name-values\n",
    "    hough_space = {}\n",
    "\n",
    "    for t_idx, q_idx in good_matches.items():\n",
    "        \n",
    "        #compute_entry_hough_space(kp_query[q_idx], kp_train[t_idx], query_xc, query_yc)\n",
    "        \n",
    "        entry = {}\n",
    "\n",
    "        v = ((q_xc - kp_q.pt[0]), (q_yc - kp_q.pt[1]))\n",
    "        scale_ratio = kp_t.size / kp_q.size\n",
    "        delta_angle = kp_t.angle - kp_q.angle\n",
    "        x_c = kp_t.pt[0] + scale_ratio * (np.cos(delta_angle) * v[0] - np.sin(delta_angle) * v[1])\n",
    "        y_c = kp_t.pt[1] + scale_ratio * (np.sin(delta_angle) * v[0] + np.cos(delta_angle) * v[1])\n",
    "\n",
    "        entry['x_c'] = x_c\n",
    "        entry['y_c'] = y_c\n",
    "        entry['scale_ratio'] = scale_ratio\n",
    "        entry['delta_angle'] = delta_angle\n",
    "    \n",
    "    hough_space[t_idx] = compute_entry_hough_space(kp_query[q_idx], kp_train[t_idx], query_xc, query_yc)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5c3b2fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<DMatch 0x7fd046adc230>,\n",
       " <DMatch 0x7fd0705cec90>,\n",
       " <DMatch 0x7fd0705d8c70>,\n",
       " <DMatch 0x7fd0705d9cd0>,\n",
       " <DMatch 0x7fd0705e1eb0>,\n",
       " <DMatch 0x7fd046af4510>,\n",
       " <DMatch 0x7fd0469bd790>,\n",
       " <DMatch 0x7fd0469bdc70>,\n",
       " <DMatch 0x7fd0469ce990>,\n",
       " <DMatch 0x7fd0469de170>,\n",
       " <DMatch 0x7fd0469de230>,\n",
       " <DMatch 0x7fd0469de290>,\n",
       " <DMatch 0x7fd0469de9f0>,\n",
       " <DMatch 0x7fd0469dec30>,\n",
       " <DMatch 0x7fd06f980250>,\n",
       " <DMatch 0x7fd046f33970>,\n",
       " <DMatch 0x7fd046b637d0>,\n",
       " <DMatch 0x7fd046b63810>,\n",
       " <DMatch 0x7fd06f9bdc90>,\n",
       " <DMatch 0x7fd06f9ab650>,\n",
       " <DMatch 0x7fd046aede90>,\n",
       " <DMatch 0x7fd046b0c590>,\n",
       " <DMatch 0x7fd046aa7f50>,\n",
       " <DMatch 0x7fd046aa6950>,\n",
       " <DMatch 0x7fd046aa6990>,\n",
       " <DMatch 0x7fd06fc2d130>,\n",
       " <DMatch 0x7fd06fc56690>,\n",
       " <DMatch 0x7fd06fc56b90>,\n",
       " <DMatch 0x7fd06fc3ba30>,\n",
       " <DMatch 0x7fd06fc3bb30>,\n",
       " <DMatch 0x7fd06fc5ddd0>,\n",
       " <DMatch 0x7fd06fc3ee90>,\n",
       " <DMatch 0x7fd06fc3eed0>,\n",
       " <DMatch 0x7fd06fb2d430>,\n",
       " <DMatch 0x7fd06fb46370>,\n",
       " <DMatch 0x7fd06fb411f0>,\n",
       " <DMatch 0x7fd06fb49850>,\n",
       " <DMatch 0x7fd06fb63190>,\n",
       " <DMatch 0x7fd06fb63d90>,\n",
       " <DMatch 0x7fd06f835c90>,\n",
       " <DMatch 0x7fd06f84eaf0>,\n",
       " <DMatch 0x7fd06f84c550>,\n",
       " <DMatch 0x7fd06fef71b0>,\n",
       " <DMatch 0x7fd06fee7190>,\n",
       " <DMatch 0x7fd06fee7250>,\n",
       " <DMatch 0x7fd06fee79d0>,\n",
       " <DMatch 0x7fd06fee7a10>,\n",
       " <DMatch 0x7fd06ff116d0>,\n",
       " <DMatch 0x7fd06ff11710>,\n",
       " <DMatch 0x7fd06ff11790>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc6c9cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
